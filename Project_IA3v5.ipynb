{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxoS3ks6jQ18"
      },
      "source": [
        "# Setup libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "rHY9MlLZm9_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aaabc8b-bf97-4003-bdb4-14c6c55e5151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy tensorflow tqdm matplotlib torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D-K4-3hj74t_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZy-QwGqjVBM"
      },
      "source": [
        "# Setup neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pNA2SCwUjZBs"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"Simple CNN for CIFAR-10 classification\"\"\"\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # 32x32 -> 16x16\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # 16x16 -> 8x8\n",
        "        x = self.pool(F.relu(self.conv3(x)))  # 8x8 -> 4x4\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oEJO58nlP33"
      },
      "source": [
        "# Attack implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rngWwdfoldfg"
      },
      "source": [
        "PGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DXirJG1alflw"
      },
      "outputs": [],
      "source": [
        "def custom_pgd_attack(model, images, labels, epsilon=8/255, alpha=2/255, num_iter=10):\n",
        "    \"\"\"Custom PGD implementation\"\"\"\n",
        "    images = images.clone().detach().to(images.device)\n",
        "    labels = labels.clone().detach().to(labels.device)\n",
        "\n",
        "    delta = torch.empty_like(images).uniform_(-epsilon, epsilon)\n",
        "    delta.requires_grad = True\n",
        "\n",
        "    for _ in range(num_iter):\n",
        "        outputs = model(images + delta)\n",
        "        loss = F.cross_entropy(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        grad_sign = delta.grad.data.sign()\n",
        "        delta.data = delta.data + alpha * grad_sign\n",
        "        delta.data = torch.clamp(delta.data, -epsilon, epsilon)\n",
        "        delta.data = torch.clamp(images.data + delta.data, 0, 1) - images.data\n",
        "\n",
        "        delta.grad.zero_()\n",
        "\n",
        "    return images + delta.detach()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlrv3t3DlgA0"
      },
      "source": [
        "DeepFool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kGYjeGOcllfF"
      },
      "outputs": [],
      "source": [
        "def custom_deepfool_attack(model, image, num_classes=10, overshoot=0.02, max_iter=50):\n",
        "    \"\"\"Custom DeepFool implementation\"\"\"\n",
        "    image = image.clone().detach().unsqueeze(0)\n",
        "    image.requires_grad = True\n",
        "\n",
        "    model.eval()\n",
        "    original_output = model(image)\n",
        "    original_label = original_output.argmax(dim=1).item()\n",
        "\n",
        "    perturb = torch.zeros_like(image)\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        outputs = model(image + perturb)\n",
        "        current_label = outputs.argmax(dim=1).item()\n",
        "\n",
        "        if current_label != original_label:\n",
        "            break\n",
        "\n",
        "        grads = []\n",
        "        for k in range(num_classes):\n",
        "            if k == original_label:\n",
        "                continue\n",
        "\n",
        "            if image.grad is not None:\n",
        "                image.grad.zero_()\n",
        "\n",
        "            outputs[0, k].backward(retain_graph=True)\n",
        "            grad = image.grad.clone()\n",
        "            grads.append(grad)\n",
        "\n",
        "        min_distance = float('inf')\n",
        "        min_grad = None\n",
        "        original_score = outputs[0, original_label]\n",
        "\n",
        "        for i, k in enumerate([j for j in range(num_classes) if j != original_label]):\n",
        "            w = grads[i].flatten()\n",
        "            f = outputs[0, k] - original_score\n",
        "            distance = abs(f.item()) / (torch.norm(w).item() + 1e-10)\n",
        "\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                min_grad = grads[i]\n",
        "\n",
        "        if min_grad is not None:\n",
        "            r = (min_distance + 1e-4) * min_grad / (torch.norm(min_grad) + 1e-10)\n",
        "            perturb = perturb + r\n",
        "\n",
        "    return (image + (1 + overshoot) * perturb).squeeze(0).detach()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defense implementations"
      ],
      "metadata": {
        "id": "NVDP-aor6gHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_jacobian_regularization(model, images, labels, lambda_reg=0.01):\n",
        "    \"\"\"\n",
        "    Compute Jacobian regularization term\n",
        "    Encourages smoothness in model predictions\n",
        "    \"\"\"\n",
        "    # Create a copy that requires gradients (don't modify original)\n",
        "    images_copy = images.detach().clone()\n",
        "    images_copy.requires_grad = True\n",
        "\n",
        "    outputs = model(images_copy)\n",
        "\n",
        "    # Standard cross-entropy loss\n",
        "    ce_loss = F.cross_entropy(outputs, labels)\n",
        "\n",
        "    # Compute Jacobian regularization (Frobenius norm of gradients)\n",
        "    jacobian_reg = 0\n",
        "    num_classes = outputs.size(1)\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        # Zero out gradients before each computation\n",
        "        if images_copy.grad is not None:\n",
        "            images_copy.grad.zero_()\n",
        "\n",
        "        # Compute gradient for this class\n",
        "        outputs_i = outputs[:, i].sum()\n",
        "        outputs_i.backward(retain_graph=True)\n",
        "\n",
        "        if images_copy.grad is not None:\n",
        "            grad_norm = torch.norm(images_copy.grad, p=2)\n",
        "            jacobian_reg += grad_norm ** 2\n",
        "\n",
        "    jacobian_reg = jacobian_reg / (num_classes * images.size(0))\n",
        "\n",
        "    total_loss = ce_loss + lambda_reg * jacobian_reg\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "eo-i4LKw6fcm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training procedures"
      ],
      "metadata": {
        "id": "20_UJP236rk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normal training"
      ],
      "metadata": {
        "id": "l59Qh4SR6vql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the k of the folds\n",
        "def train_standard(model, dataset, optimizer, device, k=5, epochs=10, patience=3):\n",
        "    \"\"\"Training with K-Fold Cross-Validation and Early Stopping\"\"\"\n",
        "    kfold = KFold(n_splits=k, shuffle=True)\n",
        "\n",
        "    fold_results = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f'\\nFold {fold + 1}/{k}')\n",
        "\n",
        "        train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
        "        val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
        "        train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "        val_loader = torch.utils.data.DataLoader(val_subset, batch_size=64, shuffle=False)\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        epochs_no_improve = 0\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            pbar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs} [Train]')\n",
        "            for images, labels in pbar:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = F.cross_entropy(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                pbar.set_postfix({'loss': total_loss/total, 'acc': 100.*correct/total})\n",
        "\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pbar_val = tqdm(val_loader, desc=f'Fold {fold + 1} [Val]')\n",
        "                for images, labels in pbar_val:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                    outputs = model(images)\n",
        "                    loss = F.cross_entropy(outputs, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                    pbar_val.set_postfix({'val_loss': val_loss/val_total, 'val_acc': 100.*val_correct/val_total})\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_loader)\n",
        "            if avg_val_loss < best_val_loss:\n",
        "                best_val_loss = avg_val_loss\n",
        "                epochs_no_improve = 0\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "                break\n",
        "\n",
        "        model.load_state_dict(best_model_wts)\n",
        "\n",
        "        fold_results.append({\n",
        "            'train_loss': total_loss / len(train_loader),\n",
        "            'train_acc': 100. * correct / total,\n",
        "            'val_loss': avg_val_loss,\n",
        "            'val_acc': 100. * val_correct / val_total\n",
        "        })\n",
        "\n",
        "    avg_train_loss = sum(f['train_loss'] for f in fold_results) / k\n",
        "    avg_train_acc = sum(f['train_acc'] for f in fold_results) / k\n",
        "    avg_val_loss = sum(f['val_loss'] for f in fold_results) / k\n",
        "    avg_val_acc = sum(f['val_acc'] for f in fold_results) / k\n",
        "\n",
        "    print(f\"\\nAverage Results after {k} folds:\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_acc:.2f}%\")\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_acc:.2f}%\")\n",
        "\n",
        "    return avg_train_loss, avg_train_acc"
      ],
      "metadata": {
        "id": "jOT5nCXnn2Gp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adversarial training"
      ],
      "metadata": {
        "id": "945tpA-j6ywB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def train_adversarial(model, dataset, optimizer, device, attack_type, epochs=10, k=5, patience=3, epsilon=8/255):\n",
        "    \"\"\"Adversarial training defense - Train on adversarial examples with K-Fold Cross-Validation and Early Stopping\"\"\"\n",
        "\n",
        "    # Hardcoded parameters for KFold and early stopping\n",
        "    kfold = KFold(n_splits=k, shuffle=True)\n",
        "    fold_results = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f'\\nFold {fold + 1}/{k}')\n",
        "\n",
        "        # Prepare the train and validation data loaders for this fold\n",
        "        train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
        "        val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
        "        train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "        val_loader = torch.utils.data.DataLoader(val_subset, batch_size=64, shuffle=False)\n",
        "\n",
        "        # Initialize early stopping parameters\n",
        "        best_val_loss = float('inf')\n",
        "        epochs_no_improve = 0\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        # Training loop for each fold\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            pbar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs} [Adversarial Training]')\n",
        "            for images, labels in pbar:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                # Generate adversarial examples using attack\n",
        "                model.eval()  # Set to eval mode for attack generation\n",
        "                adv_images = None\n",
        "                if attack_type == 'pgd':\n",
        "                  adv_images = custom_pgd_attack(model, images, labels, epsilon=epsilon)\n",
        "                elif attack_type == 'deepfool':\n",
        "                  adv_images_list = []\n",
        "                  for i in range(images.size(0)):\n",
        "                    adv_images_list.append(custom_deepfool_attack(model, images[i]))\n",
        "                  adv_images = torch.stack(adv_images_list)\n",
        "                elif attack_type == 'none':\n",
        "                  adv_images = images\n",
        "                elif attack_type == 'both':\n",
        "                  adv_images_pgd = custom_pgd_attack(model, images, labels, epsilon=epsilon)\n",
        "                  adv_images_deepfool_list = []\n",
        "                  for i in range(images.size(0)):\n",
        "                    adv_images_deepfool_list.append(custom_deepfool_attack(model, images[i]))\n",
        "                  adv_images_deepfool = torch.stack(adv_images_deepfool_list)\n",
        "\n",
        "                  # Combine the adversarial images for random sampling\n",
        "                  # Convert tensors to lists of individual images, combine, then stack back\n",
        "                  combined_adv_images_list = adv_images_pgd.unbind(0) + adv_images_deepfool.unbind(0)\n",
        "                  selected_adv_images_list = random.sample(combined_adv_images_list, len(images))\n",
        "                  adv_images = torch.stack(selected_adv_images_list)\n",
        "                model.train()  # Back to train mode\n",
        "\n",
        "                # Train on adversarial examples\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(adv_images)\n",
        "                loss = F.cross_entropy(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                pbar.set_postfix({'loss': total_loss / total, 'acc': 100. * correct / total})\n",
        "\n",
        "            # Validation step after each epoch\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pbar_val = tqdm(val_loader, desc=f'Fold {fold + 1} [Validation]')\n",
        "                for images, labels in pbar_val:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                    # Perform validation on original images (not adversarial)\n",
        "                    outputs = model(images)\n",
        "                    loss = F.cross_entropy(outputs, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                    pbar_val.set_postfix({'val_loss': val_loss / val_total, 'val_acc': 100. * val_correct / val_total})\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "            # Early stopping check\n",
        "            if avg_val_loss < best_val_loss:\n",
        "                best_val_loss = avg_val_loss\n",
        "                epochs_no_improve = 0\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())  # Save the best model weights\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            # If no improvement for 'patience' epochs, stop early\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "                break\n",
        "\n",
        "        # Restore the best model weights after training\n",
        "        model.load_state_dict(best_model_wts)\n",
        "\n",
        "        # Store the results for this fold\n",
        "        fold_results.append({\n",
        "            'train_loss': total_loss / len(train_loader),\n",
        "            'train_acc': 100. * correct / total,\n",
        "        })\n",
        "\n",
        "    # Compute average results across all folds\n",
        "    avg_train_loss = sum(f['train_loss'] for f in fold_results) / k\n",
        "    avg_train_acc = sum(f['train_acc'] for f in fold_results) / k\n",
        "\n",
        "    print(f\"\\nAverage Results after {k} folds:\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_acc:.2f}%\")\n",
        "\n",
        "    return avg_train_loss, avg_train_acc"
      ],
      "metadata": {
        "id": "CV014hF6opAv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jacobian reg. training"
      ],
      "metadata": {
        "id": "s_IFwpYH649f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K Fold training\n",
        "def train_jacobian(model, dataset, optimizer, device, epochs=10, k=5, patience=3, lambda_reg=0.01):\n",
        "    \"\"\"Train with Jacobian regularization defense with K-Fold Cross-Validation and Early Stopping\"\"\"\n",
        "\n",
        "    # Hardcoded parameters for KFold and early stopping\n",
        "    kfold = KFold(n_splits=k, shuffle=True)\n",
        "    fold_results = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f'\\nFold {fold + 1}/{k}')\n",
        "\n",
        "        # Prepare the train and validation data loaders for this fold\n",
        "        train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
        "        val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
        "        train_loader = torch.utils.data.DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "        val_loader = torch.utils.data.DataLoader(val_subset, batch_size=64, shuffle=False)\n",
        "\n",
        "        # Initialize early stopping parameters\n",
        "        best_val_loss = float('inf')\n",
        "        epochs_no_improve = 0\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        # Training loop for each fold\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            pbar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs} [Jacobian Regularization]')\n",
        "            for images, labels in pbar:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss = compute_jacobian_regularization(model, images, labels, lambda_reg)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = model(images).max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                pbar.set_postfix({'loss': total_loss / total, 'acc': 100. * correct / total})\n",
        "\n",
        "            # Validation step after each epoch\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pbar_val = tqdm(val_loader, desc=f'Fold {fold + 1} [Validation]')\n",
        "                for images, labels in pbar_val:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                    # Perform validation on original images (not adversarial)\n",
        "                    outputs = model(images)\n",
        "                    loss = F.cross_entropy(outputs, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                    pbar_val.set_postfix({'val_loss': val_loss / val_total, 'val_acc': 100. * val_correct / val_total})\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "            # Early stopping check\n",
        "            if avg_val_loss < best_val_loss:\n",
        "                best_val_loss = avg_val_loss\n",
        "                epochs_no_improve = 0\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())  # Save the best model weights\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            # If no improvement for 'patience' epochs, stop early\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "                break\n",
        "\n",
        "        # Restore the best model weights after training\n",
        "        model.load_state_dict(best_model_wts)\n",
        "\n",
        "        # Store the results for this fold\n",
        "        fold_results.append({\n",
        "            'train_loss': total_loss / len(train_loader),\n",
        "            'train_acc': 100. * correct / total,\n",
        "        })\n",
        "\n",
        "    # Compute average results across all folds\n",
        "    avg_train_loss = sum(f['train_loss'] for f in fold_results) / k\n",
        "    avg_train_acc = sum(f['train_acc'] for f in fold_results) / k\n",
        "\n",
        "    print(f\"\\nAverage Results after {k} folds:\")\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_acc:.2f}%\")\n",
        "\n",
        "    return avg_train_loss, avg_train_acc"
      ],
      "metadata": {
        "id": "6J4pYgJRo3Vn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "EN8AHKkW7Iy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def deepfool_batch(model, images):\n",
        "    # Helper function to apply custom_deepfool_attack to a batch of images\n",
        "    adv_images_list = []\n",
        "    for i in range(images.size(0)):\n",
        "        adv_images_list.append(custom_deepfool_attack(model, images[i]))\n",
        "    return torch.stack(adv_images_list)\n",
        "\n",
        "def evaluate(model, test_loader, device, attack_type=None, epsilon=8/255):\n",
        "    \"\"\"\n",
        "    Evaluate model on clean or adversarial examples\n",
        "\n",
        "    Args:\n",
        "        model: Neural network model\n",
        "        test_loader: Test data loader\n",
        "        device: Device to run on\n",
        "        attack_type: 'pgd', 'deepfool', or None for clean evaluation\n",
        "        epsilon: Attack strength\n",
        "\n",
        "    Returns:\n",
        "        Accuracy percentage, time taken\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    desc = f'Evaluating [{attack_type if attack_type else \"Clean\"}]'\n",
        "    pbar = tqdm(test_loader, desc=desc)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Generate adversarial examples if attack specified\n",
        "        if attack_type == 'pgd':\n",
        "            images = images.clone().detach().to(images.device)\n",
        "            labels = labels.clone().detach().to(labels.device)\n",
        "            images = custom_pgd_attack(model, images, labels, epsilon=epsilon)\n",
        "        elif attack_type == 'deepfool':\n",
        "             with torch.no_grad(): # DeepFool does not require gradients for the original images in the evaluation loop\n",
        "                 images = deepfool_batch(model, images)\n",
        "\n",
        "        with torch.no_grad(): # Evaluate the model without gradient computation\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            pbar.set_postfix({'acc': 100.*correct/total})\n",
        "\n",
        "    end_time = time.time()\n",
        "    accuracy = 100. * correct / total\n",
        "    time_taken = end_time - start_time\n",
        "    return accuracy, time_taken"
      ],
      "metadata": {
        "id": "fwJ-saVJ7NCa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main experiment using implementations"
      ],
      "metadata": {
        "id": "njQxcOYg7OU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Load data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train\n",
        ")\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Create model\n",
        "model = SimpleCNN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxKwAZNH96IO",
        "outputId": "ac7cbf18-7c43-41c5-d13c-24deda332813"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:27<00:00, 6.20MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_count = 10 # Define the number of epochs for the k-fold training functions\n",
        "\n",
        "train_loss, train_acc = train_standard(model, train_dataset, optimizer, device, k=5, epochs=epoch_count, patience=3)\n",
        "print(f'Standard Training Complete: Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%')\n",
        "\n",
        "# Evaluate\n",
        "clean_acc = evaluate(model, test_loader, device, attack_type=None)\n",
        "pgd_acc = evaluate(model, test_loader, device, attack_type='pgd', epsilon=8/255)\n",
        "\n",
        "print(f'Clean Accuracy: {clean_acc[0]:.2f}%')\n",
        "print(f'PGD Attack Accuracy: {pgd_acc[0]:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8s0-jkR7S99",
        "outputId": "f4b42c22-1463-4e04-d746-cf4602e18dd9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 40.00it/s, loss=0.0275, acc=34.8]\n",
            "Fold 1 [Val]: 100%|██████████| 157/157 [00:03<00:00, 50.31it/s, val_loss=0.0227, val_acc=46.4]\n",
            "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 41.00it/s, loss=0.0226, acc=47.3]\n",
            "Fold 1 [Val]: 100%|██████████| 157/157 [00:03<00:00, 49.32it/s, val_loss=0.0204, val_acc=52.3]\n",
            "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 39.87it/s, loss=0.0205, acc=52.9]\n",
            "Fold 1 [Val]: 100%|██████████| 157/157 [00:03<00:00, 49.41it/s, val_loss=0.0185, val_acc=56.7]\n",
            "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 41.66it/s, loss=0.019, acc=56.3]\n",
            "Fold 1 [Val]: 100%|██████████| 157/157 [00:03<00:00, 48.62it/s, val_loss=0.0174, val_acc=60.4]\n",
            "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 40.74it/s, loss=0.0176, acc=60.1]\n",
            "Fold 1 [Val]: 100%|██████████| 157/157 [00:03<00:00, 51.58it/s, val_loss=0.017, val_acc=61.9]\n",
            "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 41.53it/s, loss=0.0166, acc=62.5]\n",
            "Fold 1 [Val]: 100%|██████████| 157/157 [00:03<00:00, 48.16it/s, val_loss=0.0159, val_acc=63.5]\n",
            "Epoch 7/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 40.83it/s, loss=0.0158, acc=64.4]\n",
            "Fold 1 [Val]: 100%|██████████| 157/157 [00:03<00:00, 50.78it/s, val_loss=0.0146, val_acc=67.1]\n",
            "Epoch 8/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 41.72it/s, loss=0.0151, acc=65.9]\n",
            "Fold 1 [Val]: 100%|██████████| 157/157 [00:03<00:00, 47.34it/s, val_loss=0.0136, val_acc=69.4]\n",
            "Epoch 9/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 40.49it/s, loss=0.0144, acc=67.6]\n",
            "Fold 1 [Val]: 100%|██████████| 157/157 [00:03<00:00, 51.46it/s, val_loss=0.0132, val_acc=70.2]\n",
            "Epoch 10/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 41.90it/s, loss=0.014, acc=68.6]\n",
            "Fold 1 [Val]: 100%|██████████| 157/157 [00:03<00:00, 46.96it/s, val_loss=0.0129, val_acc=70.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 41.32it/s, loss=0.0138, acc=69.1]\n",
            "Fold 2 [Val]: 100%|██████████| 157/157 [00:03<00:00, 51.44it/s, val_loss=0.0129, val_acc=71]\n",
            "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 42.71it/s, loss=0.0134, acc=70]\n",
            "Fold 2 [Val]: 100%|██████████| 157/157 [00:03<00:00, 48.83it/s, val_loss=0.0124, val_acc=72.6]\n",
            "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 41.08it/s, loss=0.013, acc=71.1]\n",
            "Fold 2 [Val]: 100%|██████████| 157/157 [00:03<00:00, 51.30it/s, val_loss=0.0119, val_acc=73.2]\n",
            "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 42.11it/s, loss=0.0127, acc=71.7]\n",
            "Fold 2 [Val]: 100%|██████████| 157/157 [00:03<00:00, 49.92it/s, val_loss=0.0118, val_acc=74.2]\n",
            "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 40.67it/s, loss=0.0124, acc=72.3]\n",
            "Fold 2 [Val]: 100%|██████████| 157/157 [00:03<00:00, 51.43it/s, val_loss=0.0119, val_acc=72.8]\n",
            "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 42.11it/s, loss=0.0122, acc=72.9]\n",
            "Fold 2 [Val]: 100%|██████████| 157/157 [00:03<00:00, 49.47it/s, val_loss=0.0119, val_acc=73.4]\n",
            "Epoch 7/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 40.62it/s, loss=0.012, acc=73.2]\n",
            "Fold 2 [Val]: 100%|██████████| 157/157 [00:03<00:00, 51.32it/s, val_loss=0.0116, val_acc=74.7]\n",
            "Epoch 8/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 41.81it/s, loss=0.0119, acc=73.6]\n",
            "Fold 2 [Val]: 100%|██████████| 157/157 [00:03<00:00, 49.08it/s, val_loss=0.0115, val_acc=74.5]\n",
            "Epoch 9/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 40.64it/s, loss=0.0116, acc=74.4]\n",
            "Fold 2 [Val]: 100%|██████████| 157/157 [00:03<00:00, 50.85it/s, val_loss=0.0112, val_acc=75.2]\n",
            "Epoch 10/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 41.85it/s, loss=0.0114, acc=74.5]\n",
            "Fold 2 [Val]: 100%|██████████| 157/157 [00:03<00:00, 48.11it/s, val_loss=0.0117, val_acc=73.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 40.83it/s, loss=0.0117, acc=74.1]\n",
            "Fold 3 [Val]: 100%|██████████| 157/157 [00:03<00:00, 50.58it/s, val_loss=0.0103, val_acc=77.5]\n",
            "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 42.02it/s, loss=0.0116, acc=74.4]\n",
            "Fold 3 [Val]: 100%|██████████| 157/157 [00:03<00:00, 48.59it/s, val_loss=0.00991, val_acc=78.1]\n",
            "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 41.25it/s, loss=0.0114, acc=75]\n",
            "Fold 3 [Val]: 100%|██████████| 157/157 [00:03<00:00, 50.56it/s, val_loss=0.0101, val_acc=77.5]\n",
            "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 41.61it/s, loss=0.0111, acc=75.3]\n",
            "Fold 3 [Val]: 100%|██████████| 157/157 [00:03<00:00, 47.19it/s, val_loss=0.0105, val_acc=77.1]\n",
            "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 41.12it/s, loss=0.011, acc=75.4]\n",
            "Fold 3 [Val]: 100%|██████████| 157/157 [00:03<00:00, 50.73it/s, val_loss=0.0106, val_acc=76.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 5\n",
            "\n",
            "Fold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 42.10it/s, loss=0.0113, acc=74.9]\n",
            "Fold 4 [Val]: 100%|██████████| 157/157 [00:03<00:00, 48.35it/s, val_loss=0.0108, val_acc=75.6]\n",
            "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 41.63it/s, loss=0.0112, acc=75.1]\n",
            "Fold 4 [Val]: 100%|██████████| 157/157 [00:03<00:00, 50.31it/s, val_loss=0.0102, val_acc=76.9]\n",
            "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 42.32it/s, loss=0.011, acc=75.6]\n",
            "Fold 4 [Val]: 100%|██████████| 157/157 [00:03<00:00, 48.19it/s, val_loss=0.00985, val_acc=77.8]\n",
            "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 41.36it/s, loss=0.0108, acc=76.1]\n",
            "Fold 4 [Val]: 100%|██████████| 157/157 [00:03<00:00, 51.70it/s, val_loss=0.0102, val_acc=77]\n",
            "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 42.73it/s, loss=0.0107, acc=76.3]\n",
            "Fold 4 [Val]: 100%|██████████| 157/157 [00:03<00:00, 49.98it/s, val_loss=0.0101, val_acc=77.6]\n",
            "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 40.86it/s, loss=0.0106, acc=76.8]\n",
            "Fold 4 [Val]: 100%|██████████| 157/157 [00:03<00:00, 51.53it/s, val_loss=0.0103, val_acc=76.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 6\n",
            "\n",
            "Fold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 42.48it/s, loss=0.011, acc=75.8]\n",
            "Fold 5 [Val]: 100%|██████████| 157/157 [00:03<00:00, 51.61it/s, val_loss=0.00907, val_acc=79.7]\n",
            "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 40.66it/s, loss=0.0109, acc=76.1]\n",
            "Fold 5 [Val]: 100%|██████████| 157/157 [00:03<00:00, 51.23it/s, val_loss=0.00946, val_acc=78.9]\n",
            "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 42.22it/s, loss=0.0108, acc=76.3]\n",
            "Fold 5 [Val]: 100%|██████████| 157/157 [00:03<00:00, 50.79it/s, val_loss=0.00924, val_acc=79.6]\n",
            "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:15<00:00, 40.83it/s, loss=0.0107, acc=76.4]\n",
            "Fold 5 [Val]: 100%|██████████| 157/157 [00:03<00:00, 51.61it/s, val_loss=0.00942, val_acc=78.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 4\n",
            "\n",
            "Average Results after 5 folds:\n",
            "Train Loss: 0.7402, Train Accuracy: 74.33%\n",
            "Validation Loss: 0.6999, Validation Accuracy: 75.23%\n",
            "Standard Training Complete: Loss=0.7402, Train Acc=74.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating [Clean]: 100%|██████████| 79/79 [00:01<00:00, 52.22it/s, acc=77.9]\n",
            "Evaluating [pgd]: 100%|██████████| 79/79 [00:04<00:00, 18.06it/s, acc=0.03]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean Accuracy: 77.87%\n",
            "PGD Attack Accuracy: 0.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new model\n",
        "model_adv = SimpleCNN().to(device)\n",
        "optimizer_adv = torch.optim.Adam(model_adv.parameters(), lr=0.001)\n",
        "\n",
        "# Train with adversarial examples\n",
        "epoch_count = 10 # Number of epochs for the k-fold training\n",
        "train_loss, train_acc = train_adversarial(model_adv, train_dataset, optimizer_adv, device, attack_type='pgd', k=5, epochs=epoch_count, patience=3, epsilon=8/255)\n",
        "print(f'Adversarial Training Complete: Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%')\n",
        "\n",
        "# Evaluate\n",
        "clean_acc = evaluate(model_adv, test_loader, device, attack_type=None)\n",
        "pgd_acc = evaluate(model_adv, test_loader, device, attack_type='pgd', epsilon=8/255)\n",
        "\n",
        "print(f'Clean Accuracy: {clean_acc[0]:.2f}%')\n",
        "print(f'PGD Attack Accuracy: {pgd_acc[0]:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-plGkIrhTtMd",
        "outputId": "f2a32480-026f-4990-848f-8e08aa96a616"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.66it/s, loss=0.0346, acc=16.7]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 52.14it/s, val_loss=0.0303, val_acc=31.2]\n",
            "Epoch 2/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.77it/s, loss=0.0326, acc=22.8]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.67it/s, val_loss=0.0283, val_acc=36.2]\n",
            "Epoch 3/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.53it/s, loss=0.032, acc=24.5]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 43.80it/s, val_loss=0.0286, val_acc=37.1]\n",
            "Epoch 4/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 20.92it/s, loss=0.0317, acc=24.9]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.53it/s, val_loss=0.0274, val_acc=38.8]\n",
            "Epoch 5/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.64it/s, loss=0.0315, acc=25.3]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.23it/s, val_loss=0.0276, val_acc=39.2]\n",
            "Epoch 6/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.65it/s, loss=0.0312, acc=25.8]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.29it/s, val_loss=0.0268, val_acc=39.5]\n",
            "Epoch 7/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 20.98it/s, loss=0.0311, acc=26.2]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 42.80it/s, val_loss=0.0265, val_acc=40.7]\n",
            "Epoch 8/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.74it/s, loss=0.0309, acc=26.5]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 50.73it/s, val_loss=0.0264, val_acc=42.7]\n",
            "Epoch 9/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.44it/s, loss=0.0308, acc=27]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 49.67it/s, val_loss=0.026, val_acc=42.8]\n",
            "Epoch 10/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.56it/s, loss=0.0307, acc=27.2]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 50.25it/s, val_loss=0.0257, val_acc=43.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 20.97it/s, loss=0.0307, acc=26.8]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 43.26it/s, val_loss=0.0255, val_acc=43]\n",
            "Epoch 2/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 20.97it/s, loss=0.0307, acc=27]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.97it/s, val_loss=0.0254, val_acc=44.3]\n",
            "Epoch 3/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.38it/s, loss=0.0305, acc=27.4]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.11it/s, val_loss=0.0254, val_acc=43.5]\n",
            "Epoch 4/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.57it/s, loss=0.0306, acc=27.7]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 50.71it/s, val_loss=0.0263, val_acc=40.9]\n",
            "Epoch 5/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.80it/s, loss=0.0305, acc=27.6]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 43.44it/s, val_loss=0.0251, val_acc=43.6]\n",
            "Epoch 6/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 20.96it/s, loss=0.0305, acc=27.4]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 48.35it/s, val_loss=0.0253, val_acc=42.6]\n",
            "Epoch 7/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.53it/s, loss=0.0304, acc=27.5]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.41it/s, val_loss=0.0251, val_acc=45]\n",
            "Epoch 8/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.41it/s, loss=0.0303, acc=27.6]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 50.78it/s, val_loss=0.025, val_acc=45.8]\n",
            "Epoch 9/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.59it/s, loss=0.0304, acc=27.7]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 46.30it/s, val_loss=0.0251, val_acc=45.6]\n",
            "Epoch 10/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.79it/s, loss=0.0303, acc=27.8]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 44.99it/s, val_loss=0.0251, val_acc=44.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 21.00it/s, loss=0.0304, acc=27.5]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.67it/s, val_loss=0.0251, val_acc=45.4]\n",
            "Epoch 2/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.82it/s, loss=0.0304, acc=28]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.76it/s, val_loss=0.025, val_acc=46.7]\n",
            "Epoch 3/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 21.02it/s, loss=0.0303, acc=27.7]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 45.52it/s, val_loss=0.0251, val_acc=45.7]\n",
            "Epoch 4/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 21.10it/s, loss=0.0303, acc=27.7]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 48.12it/s, val_loss=0.0251, val_acc=45.1]\n",
            "Epoch 5/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.67it/s, loss=0.0303, acc=27.9]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 50.97it/s, val_loss=0.0249, val_acc=44.9]\n",
            "Epoch 6/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.81it/s, loss=0.0302, acc=27.7]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.83it/s, val_loss=0.0246, val_acc=45.8]\n",
            "Epoch 7/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 21.08it/s, loss=0.0302, acc=27.9]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 42.85it/s, val_loss=0.0245, val_acc=45.4]\n",
            "Epoch 8/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 20.88it/s, loss=0.0301, acc=28.2]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 48.94it/s, val_loss=0.0248, val_acc=44.7]\n",
            "Epoch 9/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.75it/s, loss=0.0302, acc=28]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 50.76it/s, val_loss=0.0245, val_acc=47]\n",
            "Epoch 10/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.67it/s, loss=0.0301, acc=28.2]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.34it/s, val_loss=0.0248, val_acc=46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 20.84it/s, loss=0.0302, acc=28.3]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 43.16it/s, val_loss=0.025, val_acc=46.1]\n",
            "Epoch 2/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 20.99it/s, loss=0.0301, acc=28.3]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 49.14it/s, val_loss=0.0249, val_acc=46.2]\n",
            "Epoch 3/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 20.91it/s, loss=0.03, acc=28.5]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.71it/s, val_loss=0.0243, val_acc=46.8]\n",
            "Epoch 4/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.82it/s, loss=0.0301, acc=28.4]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.90it/s, val_loss=0.0252, val_acc=44.9]\n",
            "Epoch 5/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 21.09it/s, loss=0.03, acc=28.7]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 43.19it/s, val_loss=0.0242, val_acc=47.2]\n",
            "Epoch 6/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 21.06it/s, loss=0.03, acc=28.4]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.29it/s, val_loss=0.0248, val_acc=46.6]\n",
            "Epoch 7/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.75it/s, loss=0.03, acc=28.5]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:02<00:00, 52.40it/s, val_loss=0.0248, val_acc=44.7]\n",
            "Epoch 8/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.68it/s, loss=0.03, acc=28.5]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.49it/s, val_loss=0.0246, val_acc=45.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 8\n",
            "\n",
            "Fold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 21.06it/s, loss=0.03, acc=28.7]\n",
            "Fold 5 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 42.93it/s, val_loss=0.0246, val_acc=46.7]\n",
            "Epoch 2/10 [Adversarial Training]: 100%|██████████| 625/625 [00:29<00:00, 20.89it/s, loss=0.03, acc=28.2]\n",
            "Fold 5 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.23it/s, val_loss=0.0248, val_acc=45.5]\n",
            "Epoch 3/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.39it/s, loss=0.03, acc=28.6]\n",
            "Fold 5 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 50.52it/s, val_loss=0.0243, val_acc=46.8]\n",
            "Epoch 4/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.39it/s, loss=0.03, acc=28.3]\n",
            "Fold 5 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.07it/s, val_loss=0.0244, val_acc=47]\n",
            "Epoch 5/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.67it/s, loss=0.0299, acc=28.3]\n",
            "Fold 5 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 41.66it/s, val_loss=0.0243, val_acc=46.6]\n",
            "Epoch 6/10 [Adversarial Training]: 100%|██████████| 625/625 [00:30<00:00, 20.65it/s, loss=0.0299, acc=28.7]\n",
            "Fold 5 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 46.97it/s, val_loss=0.0244, val_acc=46.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 6\n",
            "\n",
            "Average Results after 5 folds:\n",
            "Train Loss: 1.9332, Train Accuracy: 28.07%\n",
            "Adversarial Training Complete: Loss=1.9332, Train Acc=28.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating [Clean]: 100%|██████████| 79/79 [00:02<00:00, 36.23it/s, acc=49]\n",
            "Evaluating [pgd]: 100%|██████████| 79/79 [00:04<00:00, 17.89it/s, acc=32.1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean Accuracy: 49.01%\n",
            "PGD Attack Accuracy: 32.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new model\n",
        "model_jac = SimpleCNN().to(device)\n",
        "optimizer_jac = torch.optim.Adam(model_jac.parameters(), lr=0.001)\n",
        "\n",
        "# Train with Jacobian regularization\n",
        "epoch_count = 10 # Number of epochs for the k-fold training\n",
        "train_loss, train_acc = train_jacobian(model_jac, train_dataset, optimizer_jac, device, k=5, epochs=epoch_count, patience=3, lambda_reg=0.01)\n",
        "print(f'Jacobian Regularization Training Complete: Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%')\n",
        "\n",
        "# Evaluate\n",
        "clean_acc = evaluate(model_jac, test_loader, device, attack_type=None)\n",
        "pgd_acc = evaluate(model_jac, test_loader, device, attack_type='pgd', epsilon=8/255)\n",
        "\n",
        "print(f'Clean Accuracy: {clean_acc[0]:.2f}%')\n",
        "print(f'PGD Attack Accuracy: {pgd_acc[0]:.2f}%')"
      ],
      "metadata": {
        "id": "8j6qAH28TuVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97af5d3b-5c51-44fc-b259-0e4672a7c7a5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:26<00:00, 23.84it/s, loss=4.64e+17, acc=9.98]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 49.41it/s, val_loss=1.25e+8, val_acc=10.2]\n",
            "Epoch 2/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:26<00:00, 23.33it/s, loss=1.07e+21, acc=9.85]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 50.60it/s, val_loss=1.97e+9, val_acc=10.2]\n",
            "Epoch 3/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:25<00:00, 24.17it/s, loss=6.85e+22, acc=10]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 50.31it/s, val_loss=8.57e+9, val_acc=10.2]\n",
            "Epoch 4/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:26<00:00, 23.99it/s, loss=1.09e+24, acc=10.1]\n",
            "Fold 1 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 43.58it/s, val_loss=2.26e+10, val_acc=10.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 4\n",
            "\n",
            "Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:25<00:00, 24.13it/s, loss=6.3e+18, acc=10.1]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.70it/s, val_loss=1.36e+8, val_acc=9.54]\n",
            "Epoch 2/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:25<00:00, 24.10it/s, loss=6.71e+18, acc=9.99]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 46.44it/s, val_loss=1.4e+8, val_acc=9.54]\n",
            "Epoch 3/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:26<00:00, 23.93it/s, loss=7.32e+18, acc=10.3]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.87it/s, val_loss=1.45e+8, val_acc=9.54]\n",
            "Epoch 4/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:25<00:00, 24.14it/s, loss=8.28e+18, acc=9.93]\n",
            "Fold 2 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.42it/s, val_loss=1.54e+8, val_acc=9.54]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 4\n",
            "\n",
            "Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:26<00:00, 24.01it/s, loss=7.1e+18, acc=9.82]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 46.02it/s, val_loss=1.45e+8, val_acc=9.82]\n",
            "Epoch 2/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:25<00:00, 24.14it/s, loss=8.99e+18, acc=9.96]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.64it/s, val_loss=1.61e+8, val_acc=9.82]\n",
            "Epoch 3/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:26<00:00, 23.71it/s, loss=1.27e+19, acc=9.86]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 42.76it/s, val_loss=1.91e+8, val_acc=9.82]\n",
            "Epoch 4/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:25<00:00, 24.06it/s, loss=2.2e+19, acc=9.79]\n",
            "Fold 3 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.90it/s, val_loss=2.49e+8, val_acc=9.82]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 4\n",
            "\n",
            "Fold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:25<00:00, 24.10it/s, loss=1.14e+19, acc=10.1]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.84it/s, val_loss=1.93e+8, val_acc=10.4]\n",
            "Epoch 2/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:26<00:00, 23.61it/s, loss=3.28e+19, acc=9.79]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.73it/s, val_loss=3.34e+8, val_acc=10.4]\n",
            "Epoch 3/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:25<00:00, 24.08it/s, loss=3.22e+20, acc=9.93]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.69it/s, val_loss=1.07e+9, val_acc=10.4]\n",
            "Epoch 4/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:25<00:00, 24.09it/s, loss=2.13e+22, acc=9.99]\n",
            "Fold 4 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 42.57it/s, val_loss=6.04e+9, val_acc=10.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 4\n",
            "\n",
            "Fold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:26<00:00, 23.71it/s, loss=2.26e+19, acc=9.94]\n",
            "Fold 5 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 49.92it/s, val_loss=2.38e+8, val_acc=10]\n",
            "Epoch 2/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:26<00:00, 23.82it/s, loss=3.68e+19, acc=10]\n",
            "Fold 5 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 43.38it/s, val_loss=3.01e+8, val_acc=10]\n",
            "Epoch 3/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:26<00:00, 23.95it/s, loss=8.25e+19, acc=9.97]\n",
            "Fold 5 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.60it/s, val_loss=4.46e+8, val_acc=10]\n",
            "Epoch 4/10 [Jacobian Regularization]: 100%|██████████| 625/625 [00:25<00:00, 24.10it/s, loss=3.79e+20, acc=10.2]\n",
            "Fold 5 [Validation]: 100%|██████████| 157/157 [00:03<00:00, 51.51it/s, val_loss=9.42e+8, val_acc=10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 4\n",
            "\n",
            "Average Results after 5 folds:\n",
            "Train Loss: 14249849505903160657444864.0000, Train Accuracy: 10.00%\n",
            "Jacobian Regularization Training Complete: Loss=14249849505903160657444864.0000, Train Acc=10.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating [Clean]: 100%|██████████| 79/79 [00:02<00:00, 39.36it/s, acc=10]\n",
            "Evaluating [pgd]: 100%|██████████| 79/79 [00:04<00:00, 17.50it/s, acc=10]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean Accuracy: 10.00%\n",
            "PGD Attack Accuracy: 10.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "# Test PGD attack\n",
        "adv_images_pgd = custom_pgd_attack(model, images, labels, epsilon=8/255)\n",
        "\n",
        "# Test DeepFool attack (on single image)\n",
        "single_image = images[0]\n",
        "adv_image_deepfool = custom_deepfool_attack(model, single_image)\n",
        "\n",
        "# Compare predictions\n",
        "with torch.no_grad():\n",
        "    clean_pred = model(images).argmax(dim=1)\n",
        "    pgd_pred = model(adv_images_pgd).argmax(dim=1)\n",
        "\n",
        "print(\"Clean predictions:\", clean_pred[:10])\n",
        "print(\"PGD adversarial predictions:\", pgd_pred[:10])\n",
        "print(\"True labels:\", labels[:10])"
      ],
      "metadata": {
        "id": "HFJ5FzkmTyTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5e7533-357e-4be3-9776-a9dd90d931fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean predictions: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
            "PGD adversarial predictions: tensor([1, 1, 1, 1, 1, 1, 6, 1, 1, 1], device='cuda:0')\n",
            "True labels: tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get one image\n",
        "img = images[0].cpu()\n",
        "adv_img = adv_images_pgd[0].cpu()\n",
        "\n",
        "# Calculate perturbation\n",
        "perturbation = (adv_img - img).abs()\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "axes[0].imshow(img.permute(1, 2, 0))\n",
        "axes[0].set_title('Clean Image')\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(adv_img.permute(1, 2, 0))\n",
        "axes[1].set_title('Adversarial Image')\n",
        "axes[1].axis('off')\n",
        "\n",
        "axes[2].imshow(perturbation.permute(1, 2, 0) * 10)  # Amplified for visibility\n",
        "axes[2].set_title('Perturbation (10x)')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Max perturbation: {perturbation.max():.4f}\")\n",
        "print(f\"L2 norm: {perturbation.norm():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "1TbHcqU3T1Im",
        "outputId": "4bcb0142-258d-4b34-ed48-3645e15dc368"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max perturbation: 0.0314\n",
            "L2 norm: 1.3131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkNFYK4vsTPK"
      },
      "source": [
        "# State of the art implementations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu9aEbbuY4CJ",
        "outputId": "65c19143-c2b3-4856-f086-2aafd37e2e58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.20.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (1.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (75.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.6.0)\n",
            "Downloading adversarial_robustness_toolbox-1.20.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: adversarial-robustness-toolbox\n",
            "Successfully installed adversarial-robustness-toolbox-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# ART imports\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from art.attacks.evasion import ProjectedGradientDescent, DeepFool"
      ],
      "metadata": {
        "id": "-SEH0W2Sbiv8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparisson to custom implementation"
      ],
      "metadata": {
        "id": "w3bo3ty-Y0O4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_custom_pgd(model, test_loader, device, epsilon=8/255, max_samples=1000):\n",
        "    \"\"\"Evaluate using custom PGD implementation\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    times = []\n",
        "\n",
        "    for images, labels in tqdm(test_loader, desc='Custom PGD'):\n",
        "        if total >= max_samples:\n",
        "            break\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        start_time = time.time()\n",
        "        adv_images = custom_pgd_attack(model, images, labels, epsilon=epsilon)\n",
        "        times.append(time.time() - start_time)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(adv_images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    avg_time = np.mean(times)\n",
        "    return accuracy, avg_time\n",
        "\n",
        "\n",
        "def evaluate_art_pgd(classifier, test_loader, epsilon=8/255, max_samples=1000):\n",
        "    \"\"\"Evaluate using ART PGD implementation\"\"\"\n",
        "    pgd_attack = ProjectedGradientDescent(\n",
        "        estimator=classifier,\n",
        "        eps=epsilon,\n",
        "        eps_step=epsilon/4,\n",
        "        max_iter=10,\n",
        "        num_random_init=1,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    times = []\n",
        "\n",
        "    for images, labels in tqdm(test_loader, desc='ART PGD'):\n",
        "        if total >= max_samples:\n",
        "            break\n",
        "\n",
        "        x_batch = images.numpy()\n",
        "        y_batch = labels.numpy()\n",
        "\n",
        "        start_time = time.time()\n",
        "        x_adv = pgd_attack.generate(x=x_batch)\n",
        "        times.append(time.time() - start_time)\n",
        "\n",
        "        predictions = classifier.predict(x_adv)\n",
        "        predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "        total += len(y_batch)\n",
        "        correct += np.sum(predicted_labels == y_batch)\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    avg_time = np.mean(times)\n",
        "    return accuracy, avg_time\n",
        "\n",
        "\n",
        "\n",
        "def calculate_perturbation_metrics(model, test_loader, device, attack_fn, epsilon=8/255, max_samples=100):\n",
        "    \"\"\"Calculate L2 and L-inf norms of perturbations\"\"\"\n",
        "    model.eval()\n",
        "    l2_norms = []\n",
        "    linf_norms = []\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        if len(l2_norms) >= max_samples:\n",
        "            break\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        if 'custom' in attack_fn.__name__:\n",
        "            adv_images = attack_fn(model, images, labels, epsilon=epsilon)\n",
        "        else:\n",
        "            # For DeepFool\n",
        "            for i in range(images.size(0)):\n",
        "                if len(l2_norms) >= max_samples:\n",
        "                    break\n",
        "                adv_img = attack_fn(model, images[i])\n",
        "                perturbation = (adv_img - images[i]).abs()\n",
        "                l2_norms.append(perturbation.norm(p=2).item())\n",
        "                linf_norms.append(perturbation.max().item())\n",
        "            continue\n",
        "\n",
        "        perturbation = (adv_images - images).abs()\n",
        "        for i in range(perturbation.size(0)):\n",
        "            if len(l2_norms) >= max_samples:\n",
        "                break\n",
        "            l2_norms.append(perturbation[i].norm(p=2).item())\n",
        "            linf_norms.append(perturbation[i].max().item())\n",
        "\n",
        "    return {\n",
        "        'l2_mean': np.mean(l2_norms),\n",
        "        'l2_std': np.std(l2_norms),\n",
        "        'linf_mean': np.mean(linf_norms),\n",
        "        'linf_std': np.std(linf_norms)\n",
        "    }"
      ],
      "metadata": {
        "id": "-yl6RqYQFZz6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_custom_deepfool(model, test_loader, device, max_samples=200):\n",
        "    \"\"\"Evaluate using custom DeepFool implementation\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    times = []\n",
        "\n",
        "    for images, labels in tqdm(test_loader, desc='Custom DeepFool'):\n",
        "        if total >= max_samples:\n",
        "            break\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        for i in range(images.size(0)):\n",
        "            if total >= max_samples:\n",
        "                break\n",
        "\n",
        "            start_time = time.time()\n",
        "            adv_img = custom_deepfool_attack(model, images[i])\n",
        "            times.append(time.time() - start_time)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model(adv_img.unsqueeze(0))\n",
        "                predicted = output.argmax(dim=1).item()\n",
        "                total += 1\n",
        "                if predicted == labels[i].item():\n",
        "                    correct += 1\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    avg_time = np.mean(times)\n",
        "    return accuracy, avg_time\n",
        "\n",
        "\n",
        "def evaluate_art_deepfool(classifier, test_loader, max_samples=200):\n",
        "    \"\"\"Evaluate using ART DeepFool implementation\"\"\"\n",
        "    deepfool_attack = DeepFool(\n",
        "        classifier=classifier,\n",
        "        max_iter=50,\n",
        "        epsilon=1e-6,\n",
        "        nb_grads=10,\n",
        "        batch_size=1,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    times = []\n",
        "\n",
        "    for images, labels in tqdm(test_loader, desc='ART DeepFool'):\n",
        "        if total >= max_samples:\n",
        "            break\n",
        "\n",
        "        x_batch = images.numpy()\n",
        "        y_batch = labels.numpy()\n",
        "\n",
        "        start_time = time.time()\n",
        "        x_adv = deepfool_attack.generate(x=x_batch)\n",
        "        times.append(time.time() - start_time)\n",
        "\n",
        "        predictions = classifier.predict(x_adv)\n",
        "        predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "        total += len(y_batch)\n",
        "        correct += np.sum(predicted_labels == y_batch)\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    avg_time = np.mean(times)\n",
        "    return accuracy, avg_time"
      ],
      "metadata": {
        "id": "Idbg3pAsxwbY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"=\"*70)\n",
        "    print(\"CUSTOM vs STATE-OF-THE-ART ADVERSARIAL ML COMPARISON\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'\\nUsing device: {device}')\n",
        "\n",
        "    # Load data\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    test_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=False, download=True, transform=transform\n",
        "    )\n",
        "    test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Load or train a simple model\n",
        "    print(\"\\nTraining a simple model for comparison...\")\n",
        "    train_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True, transform=transform\n",
        "    )\n",
        "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "    model = SimpleCNN().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Quick training (3 epochs)\n",
        "    for epoch in range(1, 4):\n",
        "        model.train()\n",
        "        for images, labels in tqdm(train_loader, desc=f'Training Epoch {epoch}'):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = F.cross_entropy(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluate clean accuracy\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    clean_acc = 100. * correct / total\n",
        "    print(f\"\\nClean Accuracy: {clean_acc:.2f}%\")\n",
        "\n",
        "    # Wrap model in ART classifier\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    classifier = PyTorchClassifier(\n",
        "        model=model,\n",
        "        clip_values=(0, 1),\n",
        "        loss=criterion,\n",
        "        optimizer=optimizer,\n",
        "        input_shape=(3, 32, 32),\n",
        "        nb_classes=10,\n",
        "    )\n",
        "\n",
        "    epsilon = 8/255\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PGD ATTACK COMPARISON\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Custom PGD\n",
        "    print(\"\\n[1/2] Evaluating Custom PGD...\")\n",
        "    custom_pgd_acc, custom_pgd_time = evaluate_custom_pgd(\n",
        "        model, test_loader, device, epsilon=epsilon, max_samples=1000\n",
        "    )\n",
        "\n",
        "    # ART PGD\n",
        "    print(\"\\n[2/2] Evaluating ART PGD...\")\n",
        "    art_pgd_acc, art_pgd_time = evaluate_art_pgd(\n",
        "        classifier, test_loader, epsilon=epsilon, max_samples=1000\n",
        "    )\n",
        "\n",
        "    # Calculate perturbation metrics for PGD\n",
        "    print(\"\\nCalculating perturbation metrics for PGD...\")\n",
        "    custom_pgd_metrics = calculate_perturbation_metrics(\n",
        "        model, test_loader, device, custom_pgd_attack, epsilon=epsilon, max_samples=100\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"PGD RESULTS:\")\n",
        "    print(\"-\"*70)\n",
        "    print(f\"{'Metric':<30} {'Custom':<20} {'ART (SOTA)':<20}\")\n",
        "    print(\"-\"*70)\n",
        "    print(f\"{'Accuracy':<30} {custom_pgd_acc:<20.2f} {art_pgd_acc:<20.2f}\")\n",
        "    print(f\"{'Avg Time per Batch (s)':<30} {custom_pgd_time:<20.4f} {art_pgd_time:<20.4f}\")\n",
        "    print(f\"{'L2 Norm (mean)':<30} {custom_pgd_metrics['l2_mean']:<20.4f} {'N/A':<20}\")\n",
        "    print(f\"{'L-inf Norm (mean)':<30} {custom_pgd_metrics['linf_mean']:<20.4f} {'N/A':<20}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    improvement_acc = art_pgd_acc - custom_pgd_acc\n",
        "    improvement_time = ((custom_pgd_time - art_pgd_time) / custom_pgd_time) * 100\n",
        "\n",
        "    print(f\"\\nART vs Custom:\")\n",
        "    print(f\"  Accuracy difference: {improvement_acc:+.2f}%\")\n",
        "    print(f\"  Speed improvement: {improvement_time:+.1f}%\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DEEPFOOL ATTACK COMPARISON\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Custom DeepFool\n",
        "    print(\"\\n[1/2] Evaluating Custom DeepFool...\")\n",
        "    custom_df_acc, custom_df_time = evaluate_custom_deepfool(\n",
        "        model, test_loader, device, max_samples=200\n",
        "    )\n",
        "\n",
        "    # ART DeepFool\n",
        "    print(\"\\n[2/2] Evaluating ART DeepFool...\")\n",
        "    art_df_acc, art_df_time = evaluate_art_deepfool(\n",
        "        classifier, test_loader, max_samples=200\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"DEEPFOOL RESULTS:\")\n",
        "    print(\"-\"*70)\n",
        "    print(f\"{'Metric':<30} {'Custom':<20} {'ART (SOTA)':<20}\")\n",
        "    print(\"-\"*70)\n",
        "    print(f\"{'Accuracy':<30} {custom_df_acc:<20.2f} {art_df_acc:<20.2f}\")\n",
        "    print(f\"{'Avg Time per Sample (s)':<30} {custom_df_time:<20.4f} {art_df_time:<20.4f}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    improvement_acc_df = art_df_acc - custom_df_acc\n",
        "    improvement_time_df = ((custom_df_time - art_df_time) / custom_df_time) * 100\n",
        "\n",
        "    print(f\"\\nART vs Custom:\")\n",
        "    print(f\"  Accuracy difference: {improvement_acc_df:+.2f}%\")\n",
        "    print(f\"  Speed improvement: {improvement_time_df:+.1f}%\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nClean Accuracy: {clean_acc:.2f}%\")\n",
        "    print(f\"\\nPGD Attack:\")\n",
        "    print(f\"  Custom:    {custom_pgd_acc:.2f}% (defender wins if higher)\")\n",
        "    print(f\"  ART SOTA:  {art_pgd_acc:.2f}%\")\n",
        "    print(f\"\\nDeepFool Attack:\")\n",
        "    print(f\"  Custom:    {custom_df_acc:.2f}%\")\n",
        "    print(f\"  ART SOTA:  {art_df_acc:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "1pqGPDV2Fght",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f54fae2-a4a1-4025-e92d-add7cde0a08c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "CUSTOM vs STATE-OF-THE-ART ADVERSARIAL ML COMPARISON\n",
            "======================================================================\n",
            "\n",
            "Using device: cuda\n",
            "\n",
            "Training a simple model for comparison...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 391/391 [00:07<00:00, 50.04it/s]\n",
            "Training Epoch 2: 100%|██████████| 391/391 [00:06<00:00, 56.27it/s]\n",
            "Training Epoch 3: 100%|██████████| 391/391 [00:08<00:00, 44.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Clean Accuracy: 61.79%\n",
            "\n",
            "======================================================================\n",
            "PGD ATTACK COMPARISON\n",
            "======================================================================\n",
            "\n",
            "[1/2] Evaluating Custom PGD...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Custom PGD:  10%|█         | 10/100 [00:00<00:05, 15.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2/2] Evaluating ART PGD...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ART PGD:  10%|█         | 10/100 [00:02<00:20,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating perturbation metrics for PGD...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "PGD RESULTS:\n",
            "----------------------------------------------------------------------\n",
            "Metric                         Custom               ART (SOTA)          \n",
            "----------------------------------------------------------------------\n",
            "Accuracy                       2.90                 13.40               \n",
            "Avg Time per Batch (s)         0.0305               0.2079              \n",
            "L2 Norm (mean)                 1.5258               N/A                 \n",
            "L-inf Norm (mean)              0.0314               N/A                 \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "ART vs Custom:\n",
            "  Accuracy difference: +10.50%\n",
            "  Speed improvement: -580.8%\n",
            "\n",
            "======================================================================\n",
            "DEEPFOOL ATTACK COMPARISON\n",
            "======================================================================\n",
            "\n",
            "[1/2] Evaluating Custom DeepFool...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Custom DeepFool:   2%|▏         | 2/100 [00:25<20:33, 12.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2/2] Evaluating ART DeepFool...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ART DeepFool:   2%|▏         | 2/100 [01:01<50:22, 30.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "DEEPFOOL RESULTS:\n",
            "----------------------------------------------------------------------\n",
            "Metric                         Custom               ART (SOTA)          \n",
            "----------------------------------------------------------------------\n",
            "Accuracy                       14.00                20.50               \n",
            "Avg Time per Sample (s)        0.1244               30.7677             \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "ART vs Custom:\n",
            "  Accuracy difference: +6.50%\n",
            "  Speed improvement: -24623.4%\n",
            "\n",
            "======================================================================\n",
            "SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Clean Accuracy: 61.79%\n",
            "\n",
            "PGD Attack:\n",
            "  Custom:    2.90% (defender wins if higher)\n",
            "  ART SOTA:  13.40%\n",
            "\n",
            "DeepFool Attack:\n",
            "  Custom:    14.00%\n",
            "  ART SOTA:  20.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}